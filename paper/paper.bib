@MISC{Black2022-or,
  title     = "{EDAM}: the bioscientific data analysis ontology (update 2021)",
  author    = "Black, Melissa and Lamothe, Lucie and Eldakroury, Hager and
               Kierkegaard, Mads and Priya, Ankita and Machinda, Anne and
               Khanduja, Uttam Singh and Patoliya, Drashti and Rathi, Rashika
               and Nico, Tawah Peggy Che and Umutesi, Gloria and Blankenburg,
               Claudia and Op, Anita and Chieke, Precious and Babatunde,
               Omodolapo and Laurie, Steve and Neumann, Steffen and Schwämmle,
               Veit and Kuzmin, Ivan and Hunter, Chris and Karr, Jonathan and
               Ison, Jon and Gaignard, Alban and Brancotte, Bryan and Ménager,
               Hervé and Kalaš, Matúš",
  journal   = "F1000Research",
  publisher = "F1000 Research Limited",
  volume    =  11,
  abstract  = "Homepage: https://edamontology.org/ Source Code:
               https://github.com/edamontology/edamontology License: CC BY-SA
               4.0 EDAM [1] is a domain ontology of data analysis and data
               management in bio- and other sciences, and science-based
               applications. It comprises concepts related to analysis,
               modelling, optimisation, and data life-cycle. Targetting
               usability by diverse end users, the structure of EDAM is
               relatively simple, divided into 4 main sections: Topic Operation
               Data (incl. Identifier) Format EDAM is used in numerous
               resources, for example Bio.tools, Galaxy, Debian, or the ELIXIR
               Europe training portal TeSS. Thanks to the annotations with EDAM,
               computational tools, workflows, standards, data, and learning
               materials are easier to find, compare, choose, and integrate.
               EDAM contributes to open science by allowing semantic annotation
               of processed data, thus making the data more understandable,
               findable, and comparable. EDAM and its applications lower the
               barrier and effort for scientists and citizens alike, towards
               doing scientific research in a more open, reliable, and inclusive
               way. The main improvements in 2021 include: The addition of
               essential concepts of data management and open science Improved
               automated validation (CI) Improved contribution processes towards
               more inclusion and engagement with communities of scientific
               experts, software engineers, and volunteers Easier to contribute,
               and therefore new contributors and new collaborations. And
               welcoming more! News from the applications: Galaxy can now
               visualise the tools panel sorted by EDAM. The EDAM community
               brings together software engineers and science experts (academic,
               industrial, citizen), professionals and volunteers. It can be
               followed and contributed to via various channels. One option is
               GitHub, with dedicated repositories incl. edamontology and
               others. Other platforms for contributions to EDAM are especially
               the generic ontology browsers of the NCBO BioPortal (EDAM, EDAM
               Bioimaging [2]) and WebProtégé (EDAM, EDAM Bioimaging; free
               registration required also for viewing). The main communication
               channel is Gitter. Along with the ontology, the community has
               developed a number of tools that enhance user experience with
               EDAM: EDAM Browser [3] is a lightweight and fast web-based
               ontology browser that provides a number of user-oriented features
               such as aggregated search across various EDAM-annotated resources
               (e.g. Bio.tools, TeSS), and suggesting changes to EDAM. EDAMmap
               is a tool for text mining EDAM concepts from articles. EDAM
               Popovers is a web-browser add-on/extension for showing details of
               EDAM concepts found in a website. Great e.g. for code and textual
               data on GitHub References: [1] Ison, J., Kalaš, M., Jonassen, I.,
               Bolser, D., Uludag, M., McWilliam, H., Malone, J., Lopez, R.,
               Pettifer, S. and Rice, P. (2013). EDAM: an ontology of
               bioinformatics operations, types of data and identifiers, topics
               and formats. Bioinformatics, 29(10): 1325-1332. DOI:
               10.1093/bioinformatics/btt113 Open access [2] Matúš Kalaš, Laure
               Plantard, Joakim Lindblad, Martin Jones, Nataša Sladoje, Moritz
               A. Kirschmann, Anatole Chessel, Leandro Scholz, Fabienne Rössler,
               Laura Nicolás Sáenz, Estibaliz Gómez de Mariscal, John Bogovic,
               Alexandre Dufour, Xavier Heiligenstein, Dominic Waithe,
               Marie-Charlotte Domart, Matthia Karreman, Raf Van de Plas, Robert
               Haase, David Hörl, Lassi Paavolainen, Ivana Vrhovac Madunić, Dean
               Karaica, Arrate Muñoz-Barrutia, Paula Sampaio, Daniel Sage,
               Sebastian Munck, Ofra Golani, Josh Moore, Florian Levet, Jon
               Ison, Alban Gaignard, Hervé Ménager, Chong Zhang, Kota Miura,
               Julien Colombelli, Perrine Paul-Gilloteaux, and welcoming new
               contributors! (2020). EDAM-bioimaging: the ontology of bioimage
               informatics operations, topics, data, and formats (update 2020)
               [version 1; not peer reviewed]. F1000Research, 9(ELIXIR):162
               (Poster) DOI: 10.7490/f1000research.1117826.1 Open access [3]
               Brancotte, B., Blanchet, C. and Ménager, H. (2018). A reusable
               tree-based web-visualization to browse EDAM ontology, and
               contribute to it. J. Open Source Softw., 3(27): 698. DOI:
               10.21105/joss.00698 Open access Acknowledgement: EDAM maintainers
               and interns were supported by ELIXIR Europe, Norway, and France.
               Dr. Melissa Black and Gloria Umutesi were awarded with
               complimentary registration at ISMB/ECCB 2021, funded by the BOSC
               2021 sponsors. The list of co-authors includes the substantial
               contributors to EDAM in 2020-2021 (version 1.26), without the
               contributors specific to EDAM Biomaging, EDAM Browser, or
               EDAMmap.",
  month     =  jan,
  year      =  2022
}

@ARTICLE{Leo2024-wa,
  title     = "Recording provenance of workflow runs with {RO}-Crate",
  author    = "Leo, Simone and Crusoe, Michael R and Rodríguez-Navas, Laura and
               Sirvent, Raül and Kanitz, Alexander and De Geest, Paul and
               Wittner, Rudolf and Pireddu, Luca and Garijo, Daniel and
               Fernández, José M and Colonnelli, Iacopo and Gallo, Matej and
               Ohta, Tazro and Suetake, Hirotaka and Capella-Gutierrez, Salvador
               and de Wit, Renske and Kinoshita, Bruno P and Soiland-Reyes,
               Stian",
  journal   = "PLoS One",
  publisher = "Public Library of Science (PLoS)",
  volume    =  19,
  number    =  9,
  pages     = "e0309210",
  abstract  = "Recording the provenance of scientific computation results is key
               to the support of traceability, reproducibility and quality
               assessment of data products. Several data models have been
               explored to address this need, providing representations of
               workflow plans and their executions as well as means of packaging
               the resulting information for archiving and sharing. However,
               existing approaches tend to lack interoperable adoption across
               workflow management systems. In this work we present Workflow Run
               RO-Crate, an extension of RO-Crate (Research Object Crate) and
               Schema.org to capture the provenance of the execution of
               computational workflows at different levels of granularity and
               bundle together all their associated objects (inputs, outputs,
               code, etc.). The model is supported by a diverse, open community
               that runs regular meetings, discussing development, maintenance
               and adoption aspects. Workflow Run RO-Crate is already
               implemented by several workflow management systems, allowing
               interoperable comparisons between workflow runs from
               heterogeneous systems. We describe the model, its alignment to
               standards such as W3C PROV, and its implementation in six
               workflow systems. Finally, we illustrate the application of
               Workflow Run RO-Crate in two use cases of machine learning in the
               digital image analysis domain.",
  month     =  sep,
  year      =  2024,
  language  = "en"
}

@ARTICLE{Langer2024-pd,
  title    = "Empowering bioinformatics communities with Nextflow and nf-core",
  author   = "Langer, Björn E and Amaral, Andreia and Baudement, Marie-Odile and
              Bonath, Franziska and Charles, Mathieu and Chitneedi, Praveen
              Krishna and Clark, Emily L and Di Tommaso, Paolo and Djebali,
              Sarah and Ewels, Philip A and Eynard, Sonia and Yates, James A
              Fellows and Fischer, Daniel and Floden, Evan W and Foissac,
              Sylvain and Gabernet, Gisela and Garcia, Maxime U and Gillard,
              Gareth and Gundappa, Manu Kumar and Guyomar, Cervin and Hakkaart,
              Christopher and Hanssen, Friederike and Harrison, Peter W and
              Hörtenhuber, Matthias and Kurylo, Cyril and Kühn, Christa and
              Lagarrigue, Sandrine and Lallias, Delphine and Macqueen, Daniel J
              and Miller, Edmund and Mir-Pedrol, Júlia and Moreira, Gabriel
              Costa Monteiro and Nahnsen, Sven and Patel, Harshil and Peltzer,
              Alexander and Pitel, Frederique and Ramayo-Caldas, Yuliaxis and da
              Câmara Ribeiro-Dantas, Marcel and Rocha, Dominique and Salavati,
              Mazdak and Sokolov, Alexey and Espinosa-Carrasco, Jose and
              Notredame, Cedric and {the nf-core community.}",
  journal  = "bioRxiv",
  abstract = "AbstractStandardised analysis pipelines are an important part of
              FAIR bioinformatics research. Over the last decade, there has been
              a notable shift from point-and-click pipeline solutions such as
              Galaxy towards command-line solutions such as Nextflow and
              Snakemake. We report on recent developments in the nf-core and
              Nextflow frameworks that have led to widespread adoption across
              many scientific communities. We describe how adopting nf-core
              standards enables faster development, improved interoperability,
              and collaboration with the >8,000 members of the nf-core
              community. The recent development of Nextflow Domain-Specific
              Language 2 (DSL2) allows pipeline components to be shared and
              combined across projects. The nf-core community has harnessed this
              with a library of modules and subworkflows that can be integrated
              into any Nextflow pipeline, enabling research communities to
              progressively transition to nf-core best practices. We present a
              case study of nf-core adoption by six European research consortia,
              grouped under the EuroFAANG umbrella and dedicated to farmed
              animal genomics. We believe that the process outlined in this
              report can inspire many large consortia to seek harmonisation of
              their data analysis procedures.",
  month    =  may,
  year     =  2024
}

@ARTICLE{Ewels2020-dj,
  title     = "The nf-core framework for community-curated bioinformatics
               pipelines",
  author    = "Ewels, Philip A and Peltzer, Alexander and Fillinger, Sven and
               Patel, Harshil and Alneberg, Johannes and Wilm, Andreas and
               Garcia, Maxime Ulysse and Di Tommaso, Paolo and Nahnsen, Sven",
  journal   = "Nat. Biotechnol.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  38,
  number    =  3,
  pages     = "276--278",
  month     =  mar,
  year      =  2020,
  language  = "en"
}

@ARTICLE{Soiland-Reyes2022-yh,
  title     = "Packaging research artefacts with {RO}-Crate",
  author    = "Soiland-Reyes, Stian and Sefton, Peter and Crosas, Mercè and
               Castro, Leyla Jael and Coppens, Frederik and Fernández, José M
               and Garijo, Daniel and Grüning, Björn and La Rosa, Marco and Leo,
               Simone and Ó Carragáin, Eoghan and Portier, Marc and Trisovic,
               Ana and {RO-Crate Community} and Groth, Paul and Goble, Carole",
  journal   = "Data Sci.",
  publisher = "IOS Press",
  volume    =  5,
  number    =  2,
  pages     = "97--138",
  abstract  = "An increasing number of researchers support reproducibility by
               including pointers to and descriptions of datasets, software and
               methods in their publications. However, scientific articles may
               be ambiguous, incomplete and difficult to process by automated
               systems. In this paper we introduce RO-Crate, an open,
               community-driven, and lightweight approach to packaging research
               artefacts along with their metadata in a machine readable manner.
               RO-Crate is based on Schema.org annotations in JSON-LD, aiming to
               establish best practices to formally describe metadata in an
               accessible and practical way for their use in a wide variety of
               situations. An RO-Crate is a structured archive of all the items
               that contributed to a research outcome, including their
               identifiers, provenance, relations and annotations. As a general
               purpose packaging approach for data and their metadata, RO-Crate
               is used across multiple areas, including bioinformatics, digital
               humanities and regulatory sciences. By applying “just enough”
               Linked Data standards, RO-Crate simplifies the process of making
               research outputs FAIR while also enhancing research
               reproducibility. An RO-Crate for this article11
               https://w3id.org/ro/doi/10.5281/zenodo.5146227 is archived at
               https://doi.org/10.5281/zenodo.5146227.",
  month     =  jul,
  year      =  2022
}

@ARTICLE{Bechhofer2013-wj,
  title     = "Why linked data is not enough for scientists",
  author    = "Bechhofer, Sean and Buchan, Iain and De Roure, David and Missier,
               Paolo and Ainsworth, John and Bhagat, Jiten and Couch, Philip and
               Cruickshank, Don and Delderfield, Mark and Dunlop, Ian and
               Gamble, Matthew and Michaelides, Danius and Owen, Stuart and
               Newman, David and Sufi, Shoaib and Goble, Carole",
  journal   = "Future Gener. Comput. Syst.",
  publisher = "Elsevier BV",
  volume    =  29,
  number    =  2,
  pages     = "599--611",
  abstract  = "Scientific data represents a significant portion of the linked
               open data cloud and scientists stand to benefit from the data
               fusion capability this will afford. Publishing linked data into
               the cloud, however, does not ensure the required reusability.
               Publishing has requirements of provenance, quality, credit,
               attribution and methods to provide the reproducibility that
               enables validation of results. In this paper we make the case for
               a scientific data publication model on top of linked data and
               introduce the notion of Research Objects as first class citizens
               for sharing and publishing.",
  month     =  feb,
  year      =  2013,
  language  = "en"
}

@ARTICLE{Wilkinson2016-ig,
  title    = "The {FAIR} Guiding Principles for scientific data management and
              stewardship",
  author   = "Wilkinson, Mark D and Dumontier, Michel and Aalbersberg, I Jsbrand
              Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and
              Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz
              Bonino and Bourne, Philip E and Bouwman, Jildau and Brookes,
              Anthony J and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and
              Dumon, Olivier and Edmunds, Scott and Evelo, Chris T and Finkers,
              Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J G and
              Groth, Paul and Goble, Carole and Grethe, Jeffrey S and Heringa,
              Jaap and 't Hoen, Peter A C and Hooft, Rob and Kuhn, Tobias and
              Kok, Ruben and Kok, Joost and Lusher, Scott J and Martone, Maryann
              E and Mons, Albert and Packer, Abel L and Persson, Bengt and
              Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and
              Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry
              and Slater, Ted and Strawn, George and Swertz, Morris A and
              Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and
              Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and
              Wolstencroft, Katherine and Zhao, Jun and Mons, Barend",
  journal  = "Sci Data",
  volume   =  3,
  pages    =  160018,
  abstract = "There is an urgent need to improve the infrastructure supporting
              the reuse of scholarly data. A diverse set of
              stakeholders-representing academia, industry, funding agencies,
              and scholarly publishers-have come together to design and jointly
              endorse a concise and measureable set of principles that we refer
              to as the FAIR Data Principles. The intent is that these may act
              as a guideline for those wishing to enhance the reusability of
              their data holdings. Distinct from peer initiatives that focus on
              the human scholar, the FAIR Principles put specific emphasis on
              enhancing the ability of machines to automatically find and use
              the data, in addition to supporting its reuse by individuals. This
              Comment is the first formal publication of the FAIR Principles,
              and includes the rationale behind them, and some exemplar
              implementations in the community.",
  month    =  mar,
  year     =  2016,
  language = "en"
}

@ARTICLE{Burgin2023-ds,
  title    = "The European Nucleotide Archive in 2022",
  author   = "Burgin, Josephine and Ahamed, Alisha and Cummins, Carla and
              Devraj, Rajkumar and Gueye, Khadim and Gupta, Dipayan and Gupta,
              Vikas and Haseeb, Muhammad and Ihsan, Maira and Ivanov, Eugene and
              Jayathilaka, Suran and Balavenkataraman Kadhirvelu, Vishnukumar
              and Kumar, Manish and Lathi, Ankur and Leinonen, Rasko and
              Mansurova, Milena and McKinnon, Jasmine and O'Cathail, Colman and
              Paupério, Joana and Pesant, Stéphane and Rahman, Nadim and Rinck,
              Gabriele and Selvakumar, Sandeep and Suman, Swati and Vijayaraja,
              Senthilnathan and Waheed, Zahra and Woollard, Peter and Yuan,
              David and Zyoud, Ahmad and Burdett, Tony and Cochrane, Guy",
  journal  = "Nucleic Acids Res.",
  volume   =  51,
  number   = "D1",
  pages    = "D121--D125",
  abstract = "The European Nucleotide Archive (ENA; https://www.ebi.ac.uk/ena),
              maintained by the European Molecular Biology Laboratory's European
              Bioinformatics Institute (EMBL-EBI), offers those producing data
              an open and supported platform for the management, archiving,
              publication, and dissemination of data; and to the scientific
              community as a whole, it offers a globally comprehensive data set
              through a host of data discovery and retrieval tools. Here, we
              describe recent updates to the ENA's submission and retrieval
              services as well as focused efforts to improve connectivity,
              reusability, and interoperability of ENA data and metadata.",
  month    =  jan,
  year     =  2023,
  language = "en"
}

@ARTICLE{Richardson2023-ot,
  title    = "{MGnify}: the microbiome sequence data analysis resource in 2023",
  author   = "Richardson, Lorna and Allen, Ben and Baldi, Germana and
              Beracochea, Martin and Bileschi, Maxwell L and Burdett, Tony and
              Burgin, Josephine and Caballero-Pérez, Juan and Cochrane, Guy and
              Colwell, Lucy J and Curtis, Tom and Escobar-Zepeda, Alejandra and
              Gurbich, Tatiana A and Kale, Varsha and Korobeynikov, Anton and
              Raj, Shriya and Rogers, Alexander B and Sakharova, Ekaterina and
              Sanchez, Santiago and Wilkinson, Darren J and Finn, Robert D",
  journal  = "Nucleic Acids Res.",
  volume   =  51,
  number   = "D1",
  pages    = "D753--D759",
  abstract = "The MGnify platform (https://www.ebi.ac.uk/metagenomics)
              facilitates the assembly, analysis and archiving of
              microbiome-derived nucleic acid sequences. The platform provides
              access to taxonomic assignments and functional annotations for
              nearly half a million analyses covering metabarcoding,
              metatranscriptomic, and metagenomic datasets, which are derived
              from a wide range of different environments. Over the past 3
              years, MGnify has not only grown in terms of the number of
              datasets contained but also increased the breadth of analyses
              provided, such as the analysis of long-read sequences. The MGnify
              protein database now exceeds 2.4 billion non-redundant sequences
              predicted from metagenomic assemblies. This collection is now
              organised into a relational database making it possible to
              understand the genomic context of the protein through navigation
              back to the source assembly and sample metadata, marking a major
              improvement. To extend beyond the functional annotations already
              provided in MGnify, we have applied deep learning-based annotation
              methods. The technology underlying MGnify's Application
              Programming Interface (API) and website has been upgraded, and we
              have enabled the ability to perform downstream analysis of the
              MGnify data through the introduction of a coupled Jupyter Lab
              environment.",
  month    =  jan,
  year     =  2023,
  language = "en"
}
